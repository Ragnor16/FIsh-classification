{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Loading egg at /home/blockchain/anaconda3/lib/python3.11/site-packages/mmfashion-0.4.0-py3.11.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /home/blockchain/anaconda3/lib/python3.11/site-packages/torchvision-0.18.0-py3.11-linux-x86_64.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: pathlib in /home/blockchain/anaconda3/lib/python3.11/site-packages (1.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os.path\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = Path('/home/blockchain/Downloads/FIsh classification/images.cv_jzk6llhf18tm3k0kyttxz/data/train')\n",
    "test_path = Path('/home/blockchain/Downloads/FIsh classification/images.cv_jzk6llhf18tm3k0kyttxz/data/test')\n",
    "val_path = Path('/home/blockchain/Downloads/FIsh classification/images.cv_jzk6llhf18tm3k0kyttxz/data/val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataframe(data_path):\n",
    "\n",
    "    filepaths = list(data_path.glob(r'**/*.jpg'))\n",
    "    labels = list(map(lambda x:os.path.split(os.path.split(x)[0])[1] , filepaths))\n",
    "\n",
    "    filepaths = pd.Series(filepaths,name='Filepaths').astype(str)\n",
    "    labels = pd.Series(labels,name='Lables')\n",
    "\n",
    "    return pd.concat([filepaths,labels],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = create_dataframe(train_path)\n",
    "test_df = create_dataframe(test_path)\n",
    "val_df = create_dataframe(val_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filepaths</th>\n",
       "      <th>Lables</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/blockchain/Downloads/FIsh classification...</td>\n",
       "      <td>fish sea_food sea_bass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/blockchain/Downloads/FIsh classification...</td>\n",
       "      <td>fish sea_food sea_bass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/blockchain/Downloads/FIsh classification...</td>\n",
       "      <td>fish sea_food sea_bass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/blockchain/Downloads/FIsh classification...</td>\n",
       "      <td>fish sea_food sea_bass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/blockchain/Downloads/FIsh classification...</td>\n",
       "      <td>fish sea_food sea_bass</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Filepaths                  Lables\n",
       "0  /home/blockchain/Downloads/FIsh classification...  fish sea_food sea_bass\n",
       "1  /home/blockchain/Downloads/FIsh classification...  fish sea_food sea_bass\n",
       "2  /home/blockchain/Downloads/FIsh classification...  fish sea_food sea_bass\n",
       "3  /home/blockchain/Downloads/FIsh classification...  fish sea_food sea_bass\n",
       "4  /home/blockchain/Downloads/FIsh classification...  fish sea_food sea_bass"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filepaths</th>\n",
       "      <th>Lables</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/blockchain/Downloads/FIsh classification...</td>\n",
       "      <td>fish sea_food sea_bass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/blockchain/Downloads/FIsh classification...</td>\n",
       "      <td>fish sea_food sea_bass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/blockchain/Downloads/FIsh classification...</td>\n",
       "      <td>fish sea_food sea_bass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/blockchain/Downloads/FIsh classification...</td>\n",
       "      <td>fish sea_food sea_bass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/blockchain/Downloads/FIsh classification...</td>\n",
       "      <td>fish sea_food sea_bass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6220</th>\n",
       "      <td>/home/blockchain/Downloads/FIsh classification...</td>\n",
       "      <td>fish sea_food red_sea_bream</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6221</th>\n",
       "      <td>/home/blockchain/Downloads/FIsh classification...</td>\n",
       "      <td>fish sea_food red_sea_bream</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6222</th>\n",
       "      <td>/home/blockchain/Downloads/FIsh classification...</td>\n",
       "      <td>fish sea_food red_sea_bream</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6223</th>\n",
       "      <td>/home/blockchain/Downloads/FIsh classification...</td>\n",
       "      <td>fish sea_food red_sea_bream</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6224</th>\n",
       "      <td>/home/blockchain/Downloads/FIsh classification...</td>\n",
       "      <td>fish sea_food red_sea_bream</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6225 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Filepaths  \\\n",
       "0     /home/blockchain/Downloads/FIsh classification...   \n",
       "1     /home/blockchain/Downloads/FIsh classification...   \n",
       "2     /home/blockchain/Downloads/FIsh classification...   \n",
       "3     /home/blockchain/Downloads/FIsh classification...   \n",
       "4     /home/blockchain/Downloads/FIsh classification...   \n",
       "...                                                 ...   \n",
       "6220  /home/blockchain/Downloads/FIsh classification...   \n",
       "6221  /home/blockchain/Downloads/FIsh classification...   \n",
       "6222  /home/blockchain/Downloads/FIsh classification...   \n",
       "6223  /home/blockchain/Downloads/FIsh classification...   \n",
       "6224  /home/blockchain/Downloads/FIsh classification...   \n",
       "\n",
       "                           Lables  \n",
       "0          fish sea_food sea_bass  \n",
       "1          fish sea_food sea_bass  \n",
       "2          fish sea_food sea_bass  \n",
       "3          fish sea_food sea_bass  \n",
       "4          fish sea_food sea_bass  \n",
       "...                           ...  \n",
       "6220  fish sea_food red_sea_bream  \n",
       "6221  fish sea_food red_sea_bream  \n",
       "6222  fish sea_food red_sea_bream  \n",
       "6223  fish sea_food red_sea_bream  \n",
       "6224  fish sea_food red_sea_bream  \n",
       "\n",
       "[6225 rows x 2 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    }
   ],
   "source": [
    "print(train_df['Lables'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lables\n",
       "animal fish                         1096\n",
       "fish sea_food trout                  580\n",
       "fish sea_food red_mullet             579\n",
       "fish sea_food shrimp                 576\n",
       "fish sea_food hourse_mackerel        573\n",
       "fish sea_food red_sea_bream          571\n",
       "fish sea_food black_sea_sprat        569\n",
       "fish sea_food gilt_head_bream        566\n",
       "fish sea_food striped_red_mullet     547\n",
       "fish sea_food sea_bass               538\n",
       "animal fish bass                      30\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['Lables'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = []\n",
    "\n",
    "for category in train_df['Lables'].unique():\n",
    "    if category == \"animal fish bass\":\n",
    "        samples.append(train_df.query(\"Lables == @category\"))\n",
    "    else:\n",
    "        category_slice = train_df.query(\"Lables == @category\")\n",
    "        samples.append(category_slice.sample(200,random_state=1))\n",
    "\n",
    "\n",
    "train_df =  pd.concat(samples,axis=0).sample(frac=1.0,random_state=1).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lables\n",
       "fish sea_food sea_bass              200\n",
       "fish sea_food trout                 200\n",
       "fish sea_food gilt_head_bream       200\n",
       "fish sea_food red_sea_bream         200\n",
       "fish sea_food black_sea_sprat       200\n",
       "animal fish                         200\n",
       "fish sea_food hourse_mackerel       200\n",
       "fish sea_food striped_red_mullet    200\n",
       "fish sea_food red_mullet            200\n",
       "fish sea_food shrimp                200\n",
       "animal fish bass                     30\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['Lables'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    preprocessing_function = tf.keras.applications.mobilenet_v2.preprocess_input,\n",
    "\n",
    ")\n",
    "\n",
    "test_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    preprocessing_function = tf.keras.applications.mobilenet_v2.preprocess_input,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2030 validated image filenames belonging to 11 classes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1092 validated image filenames belonging to 11 classes.\n",
      "Found 3187 validated image filenames belonging to 11 classes.\n"
     ]
    }
   ],
   "source": [
    "train_images = train_generator.flow_from_dataframe(\n",
    "    dataframe = train_df,\n",
    "    x_col = 'Filepaths',\n",
    "    y_col = 'Lables',\n",
    "    target_size = (224,224),\n",
    "    color_mode = 'rgb',\n",
    "    class_mode = 'categorical',\n",
    "    batch_size = 32,\n",
    "    shuffle = True,\n",
    "    seed =42,\n",
    ")\n",
    "\n",
    "val_images = train_generator.flow_from_dataframe(\n",
    "    dataframe = val_df,\n",
    "    x_col = 'Filepaths',\n",
    "    y_col = 'Lables',\n",
    "    target_size = (224,224),\n",
    "    color_mode = 'rgb',\n",
    "    class_mode = 'categorical',\n",
    "    batch_size = 32,\n",
    "    shuffle = True,\n",
    "    seed =42,\n",
    ")\n",
    "\n",
    "test_images = test_generator.flow_from_dataframe(\n",
    "    dataframe = test_df,\n",
    "    x_col = 'Filepaths',\n",
    "    y_col = 'Lables',\n",
    "    target_size = (224,224),\n",
    "    color_mode = 'rgb',\n",
    "    class_mode = 'categorical',\n",
    "    batch_size = 32,\n",
    "    shuffle = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobilenet_model = tf.keras.applications.MobileNetV2(\n",
    "    input_shape = (224,224,3),\n",
    "    include_top = False,\n",
    "    weights=\"imagenet\",\n",
    "    pooling = \"avg\",\n",
    "\n",
    ")\n",
    "\n",
    "mobilenet_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobilenet_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7,\n",
       " 7,\n",
       " 10,\n",
       " 3,\n",
       " 6,\n",
       " 7,\n",
       " 2,\n",
       " 0,\n",
       " 6,\n",
       " 4,\n",
       " 10,\n",
       " 9,\n",
       " 9,\n",
       " 2,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 0,\n",
       " 3,\n",
       " 8,\n",
       " 6,\n",
       " 10,\n",
       " 9,\n",
       " 8,\n",
       " 6,\n",
       " 9,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 6,\n",
       " 4,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 9,\n",
       " 10,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 6,\n",
       " 10,\n",
       " 5,\n",
       " 0,\n",
       " 5,\n",
       " 10,\n",
       " 8,\n",
       " 9,\n",
       " 5,\n",
       " 8,\n",
       " 5,\n",
       " 7,\n",
       " 5,\n",
       " 8,\n",
       " 2,\n",
       " 10,\n",
       " 9,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 10,\n",
       " 9,\n",
       " 10,\n",
       " 7,\n",
       " 2,\n",
       " 8,\n",
       " 0,\n",
       " 7,\n",
       " 9,\n",
       " 9,\n",
       " 3,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 2,\n",
       " 8,\n",
       " 5,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 2,\n",
       " 2,\n",
       " 10,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 4,\n",
       " 8,\n",
       " 9,\n",
       " 8,\n",
       " 6,\n",
       " 0,\n",
       " 4,\n",
       " 5,\n",
       " 7,\n",
       " 2,\n",
       " 10,\n",
       " 4,\n",
       " 10,\n",
       " 3,\n",
       " 9,\n",
       " 8,\n",
       " 6,\n",
       " 4,\n",
       " 10,\n",
       " 7,\n",
       " 5,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 7,\n",
       " 0,\n",
       " 6,\n",
       " 0,\n",
       " 3,\n",
       " 7,\n",
       " 3,\n",
       " 2,\n",
       " 9,\n",
       " 5,\n",
       " 0,\n",
       " 5,\n",
       " 7,\n",
       " 10,\n",
       " 7,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 8,\n",
       " 9,\n",
       " 7,\n",
       " 9,\n",
       " 7,\n",
       " 6,\n",
       " 2,\n",
       " 7,\n",
       " 4,\n",
       " 8,\n",
       " 4,\n",
       " 3,\n",
       " 10,\n",
       " 10,\n",
       " 3,\n",
       " 10,\n",
       " 9,\n",
       " 5,\n",
       " 3,\n",
       " 0,\n",
       " 9,\n",
       " 9,\n",
       " 4,\n",
       " 8,\n",
       " 10,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 9,\n",
       " 10,\n",
       " 5,\n",
       " 10,\n",
       " 3,\n",
       " 9,\n",
       " 4,\n",
       " 3,\n",
       " 0,\n",
       " 8,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 9,\n",
       " 7,\n",
       " 10,\n",
       " 4,\n",
       " 8,\n",
       " 3,\n",
       " 6,\n",
       " 0,\n",
       " 3,\n",
       " 10,\n",
       " 6,\n",
       " 0,\n",
       " 6,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 7,\n",
       " 3,\n",
       " 7,\n",
       " 4,\n",
       " 6,\n",
       " 4,\n",
       " 9,\n",
       " 4,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 9,\n",
       " 7,\n",
       " 9,\n",
       " 3,\n",
       " 10,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 3,\n",
       " 8,\n",
       " 5,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 6,\n",
       " 9,\n",
       " 3,\n",
       " 6,\n",
       " 4,\n",
       " 10,\n",
       " 3,\n",
       " 5,\n",
       " 6,\n",
       " 4,\n",
       " 5,\n",
       " 7,\n",
       " 7,\n",
       " 0,\n",
       " 9,\n",
       " 5,\n",
       " 4,\n",
       " 10,\n",
       " 6,\n",
       " 3,\n",
       " 0,\n",
       " 5,\n",
       " 4,\n",
       " 2,\n",
       " 7,\n",
       " 3,\n",
       " 4,\n",
       " 6,\n",
       " 9,\n",
       " 5,\n",
       " 0,\n",
       " 3,\n",
       " 9,\n",
       " 10,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 9,\n",
       " 6,\n",
       " 7,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 10,\n",
       " 6,\n",
       " 10,\n",
       " 8,\n",
       " 9,\n",
       " 9,\n",
       " 0,\n",
       " 5,\n",
       " 9,\n",
       " 3,\n",
       " 4,\n",
       " 10,\n",
       " 10,\n",
       " 3,\n",
       " 7,\n",
       " 5,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 0,\n",
       " 8,\n",
       " 4,\n",
       " 8,\n",
       " 6,\n",
       " 2,\n",
       " 9,\n",
       " 6,\n",
       " 10,\n",
       " 7,\n",
       " 0,\n",
       " 10,\n",
       " 9,\n",
       " 7,\n",
       " 5,\n",
       " 8,\n",
       " 5,\n",
       " 5,\n",
       " 8,\n",
       " 3,\n",
       " 8,\n",
       " 8,\n",
       " 9,\n",
       " 2,\n",
       " 9,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 7,\n",
       " 6,\n",
       " 4,\n",
       " 0,\n",
       " 6,\n",
       " 6,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 5,\n",
       " 8,\n",
       " 8,\n",
       " 4,\n",
       " 6,\n",
       " 8,\n",
       " 2,\n",
       " 4,\n",
       " 7,\n",
       " 10,\n",
       " 10,\n",
       " 2,\n",
       " 7,\n",
       " 8,\n",
       " 3,\n",
       " 6,\n",
       " 2,\n",
       " 7,\n",
       " 2,\n",
       " 2,\n",
       " 7,\n",
       " 10,\n",
       " 0,\n",
       " 0,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 10,\n",
       " 7,\n",
       " 0,\n",
       " 7,\n",
       " 9,\n",
       " 2,\n",
       " 0,\n",
       " 6,\n",
       " 7,\n",
       " 5,\n",
       " 8,\n",
       " 8,\n",
       " 6,\n",
       " 10,\n",
       " 5,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 5,\n",
       " 8,\n",
       " 10,\n",
       " 5,\n",
       " 7,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 10,\n",
       " 5,\n",
       " 6,\n",
       " 3,\n",
       " 2,\n",
       " 7,\n",
       " 10,\n",
       " 2,\n",
       " 6,\n",
       " 2,\n",
       " 4,\n",
       " 10,\n",
       " 9,\n",
       " 5,\n",
       " 3,\n",
       " 0,\n",
       " 10,\n",
       " 9,\n",
       " 6,\n",
       " 6,\n",
       " 9,\n",
       " 10,\n",
       " 8,\n",
       " 6,\n",
       " 10,\n",
       " 8,\n",
       " 6,\n",
       " 10,\n",
       " 5,\n",
       " 5,\n",
       " 2,\n",
       " 0,\n",
       " 7,\n",
       " 7,\n",
       " 8,\n",
       " 4,\n",
       " 7,\n",
       " 8,\n",
       " 5,\n",
       " 8,\n",
       " 6,\n",
       " 6,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 0,\n",
       " 8,\n",
       " 2,\n",
       " 2,\n",
       " 6,\n",
       " 3,\n",
       " 10,\n",
       " 2,\n",
       " 2,\n",
       " 6,\n",
       " 7,\n",
       " 6,\n",
       " 5,\n",
       " 1,\n",
       " 0,\n",
       " 10,\n",
       " 4,\n",
       " 5,\n",
       " 7,\n",
       " 6,\n",
       " 8,\n",
       " 10,\n",
       " 9,\n",
       " 6,\n",
       " 10,\n",
       " 6,\n",
       " 9,\n",
       " 7,\n",
       " 0,\n",
       " 9,\n",
       " 9,\n",
       " 8,\n",
       " 2,\n",
       " 8,\n",
       " 3,\n",
       " 2,\n",
       " 9,\n",
       " 9,\n",
       " 10,\n",
       " 10,\n",
       " 4,\n",
       " 3,\n",
       " 7,\n",
       " 9,\n",
       " 10,\n",
       " 8,\n",
       " 9,\n",
       " 5,\n",
       " 2,\n",
       " 8,\n",
       " 9,\n",
       " 8,\n",
       " 5,\n",
       " 10,\n",
       " 10,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 7,\n",
       " 4,\n",
       " 6,\n",
       " 3,\n",
       " 5,\n",
       " 9,\n",
       " 7,\n",
       " 8,\n",
       " 4,\n",
       " 8,\n",
       " 7,\n",
       " 4,\n",
       " 5,\n",
       " 9,\n",
       " 10,\n",
       " 3,\n",
       " 5,\n",
       " 6,\n",
       " 0,\n",
       " 6,\n",
       " 4,\n",
       " 0,\n",
       " 8,\n",
       " 2,\n",
       " 8,\n",
       " 1,\n",
       " 9,\n",
       " 6,\n",
       " 6,\n",
       " 10,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 6,\n",
       " 8,\n",
       " 6,\n",
       " 8,\n",
       " 9,\n",
       " 2,\n",
       " 5,\n",
       " 10,\n",
       " 8,\n",
       " 2,\n",
       " 3,\n",
       " 7,\n",
       " 7,\n",
       " 10,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 6,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 5,\n",
       " 7,\n",
       " 9,\n",
       " 5,\n",
       " 6,\n",
       " 2,\n",
       " 4,\n",
       " 9,\n",
       " 0,\n",
       " 4,\n",
       " 10,\n",
       " 10,\n",
       " 3,\n",
       " 9,\n",
       " 8,\n",
       " 6,\n",
       " 7,\n",
       " 10,\n",
       " 3,\n",
       " 10,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 9,\n",
       " 2,\n",
       " 8,\n",
       " 0,\n",
       " 7,\n",
       " 3,\n",
       " 7,\n",
       " 5,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 8,\n",
       " 7,\n",
       " 6,\n",
       " 2,\n",
       " 5,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 9,\n",
       " 5,\n",
       " 8,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 9,\n",
       " 7,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 0,\n",
       " 6,\n",
       " 10,\n",
       " 0,\n",
       " 5,\n",
       " 7,\n",
       " 2,\n",
       " 3,\n",
       " 6,\n",
       " 6,\n",
       " 3,\n",
       " 2,\n",
       " 7,\n",
       " 2,\n",
       " 5,\n",
       " 0,\n",
       " 10,\n",
       " 0,\n",
       " 5,\n",
       " 5,\n",
       " 7,\n",
       " 5,\n",
       " 10,\n",
       " 6,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 5,\n",
       " 7,\n",
       " 3,\n",
       " 3,\n",
       " 7,\n",
       " 3,\n",
       " 4,\n",
       " 0,\n",
       " 5,\n",
       " 8,\n",
       " 0,\n",
       " 4,\n",
       " 8,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 8,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 9,\n",
       " 0,\n",
       " 5,\n",
       " 9,\n",
       " 0,\n",
       " 7,\n",
       " 4,\n",
       " 10,\n",
       " 7,\n",
       " 4,\n",
       " 2,\n",
       " 7,\n",
       " 0,\n",
       " 3,\n",
       " 5,\n",
       " 2,\n",
       " 9,\n",
       " 5,\n",
       " 7,\n",
       " 8,\n",
       " 7,\n",
       " 9,\n",
       " 9,\n",
       " 2,\n",
       " 3,\n",
       " 7,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 9,\n",
       " 8,\n",
       " 10,\n",
       " 8,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 8,\n",
       " 8,\n",
       " 4,\n",
       " 7,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 10,\n",
       " 9,\n",
       " 9,\n",
       " 5,\n",
       " 5,\n",
       " 6,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 8,\n",
       " 4,\n",
       " 5,\n",
       " 10,\n",
       " 2,\n",
       " 5,\n",
       " 3,\n",
       " 8,\n",
       " 6,\n",
       " 7,\n",
       " 0,\n",
       " 8,\n",
       " 2,\n",
       " 8,\n",
       " 8,\n",
       " 0,\n",
       " 8,\n",
       " 8,\n",
       " 5,\n",
       " 9,\n",
       " 9,\n",
       " 8,\n",
       " 5,\n",
       " 6,\n",
       " 0,\n",
       " 7,\n",
       " 6,\n",
       " 1,\n",
       " 6,\n",
       " 10,\n",
       " 5,\n",
       " 4,\n",
       " 8,\n",
       " 7,\n",
       " 5,\n",
       " 8,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 10,\n",
       " 10,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 10,\n",
       " 0,\n",
       " 2,\n",
       " 7,\n",
       " 3,\n",
       " 9,\n",
       " 8,\n",
       " 9,\n",
       " 3,\n",
       " 8,\n",
       " 0,\n",
       " 9,\n",
       " 0,\n",
       " 10,\n",
       " 6,\n",
       " 8,\n",
       " 10,\n",
       " 7,\n",
       " 10,\n",
       " 6,\n",
       " 8,\n",
       " 2,\n",
       " 3,\n",
       " 7,\n",
       " 0,\n",
       " 4,\n",
       " 5,\n",
       " 0,\n",
       " 8,\n",
       " 2,\n",
       " 5,\n",
       " 6,\n",
       " 10,\n",
       " 9,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 6,\n",
       " 10,\n",
       " 10,\n",
       " 9,\n",
       " 5,\n",
       " 0,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 0,\n",
       " 4,\n",
       " 2,\n",
       " 9,\n",
       " 8,\n",
       " 9,\n",
       " 0,\n",
       " 2,\n",
       " 4,\n",
       " 8,\n",
       " 5,\n",
       " 3,\n",
       " 7,\n",
       " 8,\n",
       " 3,\n",
       " 9,\n",
       " 4,\n",
       " 5,\n",
       " 8,\n",
       " 9,\n",
       " 2,\n",
       " 9,\n",
       " 2,\n",
       " 8,\n",
       " 8,\n",
       " 5,\n",
       " 9,\n",
       " 7,\n",
       " 7,\n",
       " 4,\n",
       " 10,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 7,\n",
       " 3,\n",
       " 10,\n",
       " 0,\n",
       " 7,\n",
       " 1,\n",
       " 5,\n",
       " 2,\n",
       " 7,\n",
       " 2,\n",
       " 9,\n",
       " 5,\n",
       " 5,\n",
       " 10,\n",
       " 9,\n",
       " 7,\n",
       " 2,\n",
       " 6,\n",
       " 9,\n",
       " 8,\n",
       " 5,\n",
       " 5,\n",
       " 0,\n",
       " 10,\n",
       " 9,\n",
       " 10,\n",
       " 0,\n",
       " 4,\n",
       " 6,\n",
       " 0,\n",
       " 8,\n",
       " 4,\n",
       " 10,\n",
       " 4,\n",
       " 10,\n",
       " 8,\n",
       " 5,\n",
       " 8,\n",
       " 6,\n",
       " 3,\n",
       " 2,\n",
       " 6,\n",
       " 3,\n",
       " 10,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 4,\n",
       " 9,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 9,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 8,\n",
       " 5,\n",
       " 4,\n",
       " 10,\n",
       " 4,\n",
       " 2,\n",
       " 0,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 7,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 10,\n",
       " 6,\n",
       " 3,\n",
       " 3,\n",
       " 7,\n",
       " 7,\n",
       " 9,\n",
       " 4,\n",
       " 10,\n",
       " 6,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 8,\n",
       " 7,\n",
       " 5,\n",
       " 8,\n",
       " 7,\n",
       " 5,\n",
       " 2,\n",
       " 6,\n",
       " 8,\n",
       " 9,\n",
       " 8,\n",
       " 9,\n",
       " 4,\n",
       " 6,\n",
       " 0,\n",
       " 10,\n",
       " 8,\n",
       " 7,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 8,\n",
       " 5,\n",
       " 5,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 5,\n",
       " 9,\n",
       " 8,\n",
       " 8,\n",
       " 3,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 8,\n",
       " 6,\n",
       " 6,\n",
       " 9,\n",
       " 0,\n",
       " 9,\n",
       " 6,\n",
       " 10,\n",
       " 10,\n",
       " 1,\n",
       " 2,\n",
       " 5,\n",
       " 3,\n",
       " 4,\n",
       " 9,\n",
       " 1,\n",
       " 10,\n",
       " 7,\n",
       " 8,\n",
       " 8,\n",
       " 10,\n",
       " 0,\n",
       " 9,\n",
       " 8,\n",
       " 6,\n",
       " 2,\n",
       " 4,\n",
       " 7,\n",
       " 5,\n",
       " 3,\n",
       " 10,\n",
       " 0,\n",
       " 10,\n",
       " 0,\n",
       " 8,\n",
       " 2,\n",
       " 10,\n",
       " 3,\n",
       " 10,\n",
       " 10,\n",
       " 5,\n",
       " 7,\n",
       " 7,\n",
       " 4,\n",
       " 7,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 6,\n",
       " 9,\n",
       " 5,\n",
       " 10,\n",
       " 0,\n",
       " ...]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 305ms/step - accuracy: 0.5796 - loss: 1.4948 - val_accuracy: 0.9643 - val_loss: 0.1320\n",
      "Epoch 2/10\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 283ms/step - accuracy: 0.9795 - loss: 0.0826 - val_accuracy: 0.9780 - val_loss: 0.0730\n",
      "Epoch 3/10\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 287ms/step - accuracy: 0.9969 - loss: 0.0255 - val_accuracy: 0.9799 - val_loss: 0.0667\n",
      "Epoch 4/10\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 278ms/step - accuracy: 0.9988 - loss: 0.0149 - val_accuracy: 0.9835 - val_loss: 0.0481\n",
      "Epoch 5/10\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 270ms/step - accuracy: 1.0000 - loss: 0.0057 - val_accuracy: 0.9844 - val_loss: 0.0444\n",
      "Epoch 6/10\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 288ms/step - accuracy: 1.0000 - loss: 0.0035 - val_accuracy: 0.9863 - val_loss: 0.0422\n",
      "Epoch 7/10\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 281ms/step - accuracy: 1.0000 - loss: 0.0025 - val_accuracy: 0.9890 - val_loss: 0.0377\n",
      "Epoch 8/10\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 277ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 0.9853 - val_loss: 0.0391\n",
      "Epoch 9/10\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 281ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.9890 - val_loss: 0.0364\n",
      "Epoch 10/10\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 292ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.9890 - val_loss: 0.0372\n"
     ]
    }
   ],
   "source": [
    "inputs = mobilenet_model.input\n",
    "\n",
    "x = tf.keras.layers.Dense(128,activation='relu')(mobilenet_model.output)\n",
    "x = tf.keras.layers.Dense(128,activation='relu')(x)\n",
    "\n",
    "outputs = tf.keras.layers.Dense(11,activation='softmax')(x)\n",
    "\n",
    "model = tf.keras.Model(inputs = inputs,outputs = outputs)\n",
    "\n",
    "model.compile(  \n",
    "    optimizer = 'adam',\n",
    "    loss = 'categorical_crossentropy',\n",
    "    metrics = ['accuracy']\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    train_images,\n",
    "    validation_data = val_images,\n",
    "    epochs =10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.023985236883163452, 0.9927831888198853]\n",
      "test loss:\n",
      "test accuracy:\n"
     ]
    }
   ],
   "source": [
    "result = model.evaluate(test_images,verbose = 0)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "Predicted Class Index: 6\n",
      "Predicted Class Name: fish sea_food red_sea_bream\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "# Load and preprocess the image\n",
    "def load_and_preprocess_image(img_path, target_size=(224, 224)):  # Adjust size based on your model\n",
    "    img = image.load_img(img_path, target_size=target_size)\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
    "    img_array = img_array / 255.0  # Normalize if needed\n",
    "    return img_array\n",
    "\n",
    "# Path to the image you want to test\n",
    "img_path = \"images.cv_jzk6llhf18tm3k0kyttxz/data/val/fish sea_food red_sea_bream/2KVXTG8MLUAH.jpg\"\n",
    "\n",
    "# Load and preprocess the image\n",
    "img_array = load_and_preprocess_image(img_path)\n",
    "\n",
    "# Get predictions\n",
    "predictions = model.predict(img_array)\n",
    "\n",
    "# Get the class with the highest probability\n",
    "predicted_class = np.argmax(predictions, axis=1)[0]\n",
    "\n",
    "# Print results\n",
    "print(f\"Predicted Class Index: {predicted_class}\")\n",
    "\n",
    "# If you have class names (labels), map the index to the label\n",
    "class_names = sorted(train_df['Lables'].unique())  # Replace with actual class labels\n",
    "print(f\"Predicted Class Name: {class_names[predicted_class]}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
